<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.32.4" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>4DV006 - Machine learning 1 (5 hec) &middot; Civilingenjör i mjukvaruteknik</title>

  
  <link rel="stylesheet" href="https://morganericsson.github.io/msengcs/css/print.css" media="print">
  <link rel="stylesheet" href="https://morganericsson.github.io/msengcs/css/poole.css">
  <link rel="stylesheet" href="https://morganericsson.github.io/msengcs/css/syntax.css">
  <link rel="stylesheet" href="https://morganericsson.github.io/msengcs/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Civilingenjör i mjukvaruteknik" />
</head>

  <body class=" ">
  <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://morganericsson.github.io/msengcs/"><h1>Civilingenjör i mjukvaruteknik</h1></a>
      <p class="lead">
       Ett utbildningskoncept under utveckling vid Linnéuniversitetet. Kontakt: morgan.ericsson@lnu.se 
      </p>
    </div>

    <ul class="sidebar-nav">
      <li><a href="https://morganericsson.github.io/msengcs/">Hem</a> </li>
      <li><a href="/msengcs/descs/"> Kursplaner </a></li><li><a href="/msengcs/utbplan/"> Utbildningsplan </a></li>
    </ul>

  </div>
</div>

    <div class="content container">
    <div class="post">
  

<h1 id="4dv006-machine-learning-1-5-hec">4DV006 - Machine learning 1 (5 hec)</h1>

<h2 id="prerequisites">Prerequisites</h2>

<ol>
<li>Linear algebra: basic knowledge about linear algebra</li>
<li>Probability theory and statistics: probability, random variable, conditional probability</li>
<li>Multivariable calculus: gradients, partial derivatives</li>
<li>Programming: knowledge in some programming language</li>
</ol>

<h2 id="learnings-outcomes">Learnings outcomes</h2>

<p>After completing the course the student is expected to:</p>

<p><em>1. Knowledge and understanding</em></p>

<ol>
<li>Describe the principles and applications of machine learning</li>
<li>Describe weaknesses and advantages of different machine learning algorithms</li>
<li>Describe the different learning paradigms in machine learning</li>
</ol>

<p><em>2. Skills and abilities</em></p>

<ol>
<li>Be able to implement algorithms to solve typical machine learning problems</li>
<li>Be able to represent data to facilitate learning</li>
<li>Be able to evaluate the performance of a model and select an appropriate model among others</li>
</ol>

<p><em>3. Judgement and approach</em></p>

<ol>
<li>Recognize typical effects of bad initialization and parameter selection and suggest ways to improve the results</li>
<li>Recognize model overfitting and underfitting and suggest ways to make improvements</li>
</ol>

<h2 id="course-contents">Course contents</h2>

<p>The course covers machine learning concepts and methods. The following topics are covered in the course:</p>

<ul>
<li>basic principles of machine learning</li>
<li>data preprocessing, feature extraction and dimensionality reduction</li>
<li>model selection, generalization, overfitting</li>
<li>optimization for training machine learning models</li>
<li>regression</li>
<li>nearest neighbor classifiers</li>
<li>logistic regression</li>
<li>naïve Bayes</li>
<li>decision trees</li>
<li>artificial neural networks</li>
<li>ensamble methods</li>
<li>kernel methods and support vector machines</li>
<li>k-means clustering and hierarchical clustering</li>
</ul>

<h2 id="modules">Modules</h2>

<ol>
<li>Important tools and methods for supervised machine learning.</li>
<li>Introduction to unsupervised learning</li>
</ol>

<h2 id="examination">Examination</h2>

<p>The examination is based on:</p>

<ul>
<li>Module 1: Assignments (A1, A2, A3)</li>
<li>Module 2: Assignments (A4)</li>

<li><p>Final: Written Exam (WE)</p>

<table>
<thead>
<tr>
<th></th>
<th>A1</th>
<th>A2</th>
<th>A3</th>
<th>A4</th>
<th>WE</th>
</tr>
</thead>

<tbody>
<tr>
<td>1.1</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>X</td>
</tr>

<tr>
<td>1.2</td>
<td>X</td>
<td></td>
<td>X</td>
<td></td>
<td>X</td>
</tr>

<tr>
<td>1.3</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>X</td>
</tr>

<tr>
<td>2.1</td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
<td></td>
</tr>

<tr>
<td>2.2</td>
<td></td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
</tr>

<tr>
<td>2.3</td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
</tr>

<tr>
<td>3.1</td>
<td></td>
<td>X</td>
<td>X</td>
<td></td>
<td>X</td>
</tr>

<tr>
<td>3.2</td>
<td></td>
<td>X</td>
<td>X</td>
<td></td>
<td>X</td>
</tr>
</tbody>
</table></li>
</ul>

<h2 id="grading">Grading</h2>

<p>The course is assessed with the grades A, B, C, D, E, Fx or F.
The grade A constitutes the highest grade on the scale and the remaining grades follow in descending order where the grade E is the lowest grade on the scale that will result in a pass.
The grade F means that the student’s performance is assessed as fail.</p>

<h2 id="course-literature">Course literature</h2>

<ul>
<li>Bishop, Christopher M. (2006). Pattern recognition and machine learning. New York, NY: Springer.</li>
<li>James, Gareth, Witten, Daniela, Hastie, Trevor &amp; Tibshirani, Robert, An introduction to statistical learning: with applications in R, Springer, New York, NY, 2013.</li>
<li>Supplementary literature may be provided by the institution if needed.</li>
</ul>

</div>
    </div>

    
  </body>
</html>