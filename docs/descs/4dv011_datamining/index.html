<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.32.4" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>4DV011 - Data mining (5 hec) &middot; Civilingenjör i mjukvaruteknik</title>

  
  <link rel="stylesheet" href="https://morganericsson.github.io/msengcs/css/print.css" media="print">
  <link rel="stylesheet" href="https://morganericsson.github.io/msengcs/css/poole.css">
  <link rel="stylesheet" href="https://morganericsson.github.io/msengcs/css/syntax.css">
  <link rel="stylesheet" href="https://morganericsson.github.io/msengcs/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Civilingenjör i mjukvaruteknik" />
</head>

  <body class=" ">
  <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://morganericsson.github.io/msengcs/"><h1>Civilingenjör i mjukvaruteknik</h1></a>
      <p class="lead">
       Ett utbildningskoncept under utveckling vid Linnéuniversitetet. Kontakt: morgan.ericsson@lnu.se 
      </p>
    </div>

    <ul class="sidebar-nav">
      <li><a href="https://morganericsson.github.io/msengcs/">Hem</a> </li>
      <li><a href="/msengcs/descs/"> Kursplaner </a></li><li><a href="/msengcs/utbplan/"> Utbildningsplan </a></li>
    </ul>

  </div>
</div>

    <div class="content container">
    <div class="post">
  

<h1 id="4dv011-data-mining-5-hec">4DV011 - Data mining (5 hec)</h1>

<h2 id="prerequisites">Prerequisites</h2>

<ul>
<li>Java programming and corresponding data structures, 1DV001</li>
<li>Algorithms, 1DV006</li>
<li>Vector and matrix calculus, 1MA002</li>
<li>Logarithmic and exponential functions, 1MA003</li>
</ul>

<h2 id="learnings-outcomes">Learnings outcomes</h2>

<p>After completing the course the student is expected to:</p>

<p><em>1. Knowledge and understanding</em></p>

<ol>
<li>Describe the foundational concepts underlying data mining</li>
<li>Define and explain algorithms and concepts for search engines, recommendation systems and clustering</li>
<li>Define and explain algorithms and concepts for data quality and preprocessing, dimensionality reduction and similarity and dissimilarity</li>
</ol>

<p><em>2. Skills and abilities</em></p>

<ol>
<li>Perform and implement algorithms for clustering</li>
<li>Perform and implement techniques for data preprocessing and dimensionality reduction using common libraries</li>
</ol>

<p><em>3. Judgement and approach</em></p>

<ol>
<li>Reflect upon the properties of different algorithms and pick those suitable for the problem to be solved</li>
<li>Reason about the impact that choices, e.g., specific algorithms and data representations, have on system performance and quality</li>
</ol>

<h2 id="course-contents">Course contents</h2>

<p>Data mining is an area aiming to give meaning to unstructured data. This course offers an introduction into data mining and includes common data mining
tasks suchs as search engines, recommendation systems and clustering. The course also includes important techniques used in data mining systems such as
finding similar or dissimilar items, evaluating data quality and perform data preprocessing and dimensionality reduction of data.</p>

<h2 id="types-of-instruction">Types of Instruction</h2>

<p>The types of instruction for this course encompass traditional lectures for teaching the majority of the course content. In addition, the content is exercised and deepened
in context of practical lab assignments. All assignments are carried out individually or in fixed groups of maximal two students.</p>

<h2 id="modules">Modules</h2>

<ul>
<li>Practical assignments, 2.5 credits</li>
<li>Theoretical assignment, 2.5 credits</li>
</ul>

<h2 id="examination">Examination</h2>

<p>The learning outcomes of this course are assessed with the help of a written exam (WE) to evaluate knowledge and understanding of data mining concepts teached in the lectures.
These theoretical assignments also contain higher level questions in order to assess if the students are able to critically reflect upon the different approaches and what impact
these may have on the performance and quality of data mining systems. In addition, 2 programming assignments (PA) are used to mainly evaluate the students’ skills in algorithm
implementation and practical use of common APIs and libraries for data mining tasks.</p>

<h2 id="grading">Grading</h2>

<p>The course is assessed with an A-F grading. The two modules are separately evaluated and graded. The WE and 2 PAs in the two modules must be passed individually. If one
of the modules is failed, then final course grade is F. If both are passed, the final course grade is an A-F grade based on the combination of the points received for the two
modules, and both of them are equally weighted. In more detail, total grade points = WE points / 2 + PA points / 2. To pass a module or the entire course, the student needs at
least 50% of the points, otherwise the course is failed. The grading table is provided in the following:</p>

<table>
<thead>
<tr>
<th>Final Grade (A-F)</th>
<th>Grading Points (%)</th>
</tr>
</thead>

<tbody>
<tr>
<td>A</td>
<td>&gt;= 90</td>
</tr>

<tr>
<td>B</td>
<td>&gt;= 80</td>
</tr>

<tr>
<td>C</td>
<td>&gt;= 70</td>
</tr>

<tr>
<td>D</td>
<td>&gt;= 60</td>
</tr>

<tr>
<td>E</td>
<td>&gt;= 50</td>
</tr>
</tbody>
</table>

<p>In order to relate the learning outcomes to the two assessment types and individual assignments, we provide the following table:</p>

<table>
<thead>
<tr>
<th>-</th>
<th>WE</th>
<th>PA1</th>
<th>PA2</th>
</tr>
</thead>

<tbody>
<tr>
<td>1.1</td>
<td>X</td>
<td>X</td>
<td>X</td>
</tr>

<tr>
<td>1.2</td>
<td>X</td>
<td>X</td>
<td></td>
</tr>

<tr>
<td>1.3</td>
<td>X</td>
<td></td>
<td>X</td>
</tr>

<tr>
<td>2.1</td>
<td></td>
<td>X</td>
<td></td>
</tr>

<tr>
<td>2.2</td>
<td></td>
<td></td>
<td>X</td>
</tr>

<tr>
<td>3.1</td>
<td></td>
<td>X</td>
<td>X</td>
</tr>

<tr>
<td>3.2</td>
<td></td>
<td>X</td>
<td>X</td>
</tr>
</tbody>
</table>

<h2 id="literature">Literature</h2>

<ul>
<li>Jure Leskovec, Anand Rajaraman and Jeff Ullman. Mining of Massive Datasets.Cambridge University Press, 2014. Available for free online at <a href="http://mmds.org/#ver21">http://mmds.org/#ver21</a>. Estimated reading: 380 / 511 pages</li>
</ul>

</div>
    </div>

    
  </body>
</html>